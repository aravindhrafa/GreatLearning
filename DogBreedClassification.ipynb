{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FA3MLi_qIX5x",
    "outputId": "39752ee0-4b04-4e85-e9b9-16b2a62f1df1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "U1s9xJVLIgIW",
    "outputId": "888a68fc-6c1c-433d-f31e-5df27e242a1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j1upVPfOIsU7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "import cv2\n",
    "import scipy.misc\n",
    "from skimage import transform\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from skimage.transform import resize\n",
    "from keras.models import Model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "batch_size =128\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JF06H54mIzax"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "total_data_path = '/content/drive/My Drive/computervision_assignment2/train.zip (Unzipped Files)/'\n",
    "train_path ='/content/drive/My Drive/computervision_assignment2/train.zip (Unzipped Files)/train/'\n",
    "test_path = '/content/drive/My Drive/computervision_assignment2/test.zip (Unzipped Files)/test/'\n",
    "labels_path ='/content/drive/My Drive/computervision_assignment2/labels.csv.zip (Unzipped Files)/labels.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YGQEiTQ4I4P9"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile(\"/content/drive/My Drive/computervision_assignment2/test.zip\",\"r\") as z:\n",
    "  z.extractall()\n",
    "\n",
    "  # zip file extraction for the test dataset\n",
    "\n",
    "\n",
    "from zipfile import ZipFile \n",
    "with ZipFile('/content/drive/My Drive/computervision_assignment2/train.zip','r') as z:\n",
    "  z.extractall()\n",
    "\n",
    "  # Zip file extraction for the train dataset\n",
    "\n",
    "from zipfile import ZipFile \n",
    "with ZipFile('/content/drive/My Drive/computervision_assignment2/labels.csv.zip','r') as z:\n",
    "  z.extractall()\n",
    "\n",
    "  # Label zip file extraction \n",
    "\n",
    "\n",
    "from zipfile import ZipFile\n",
    "with ZipFile('/content/drive/My Drive/computervision_assignment2/sample_submission.csv.zip','r') as z:\n",
    "  z.extractall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "colab_type": "code",
    "id": "CHKazBBfLopQ",
    "outputId": "1ae0dac1-d591-4b69-8460-c8ea737516d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>002211c81b498ef88e1b40b9abf84e1d</td>\n",
       "      <td>bedlington_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00290d3e1fdd27226ba27a8ce248ce85</td>\n",
       "      <td>bedlington_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>002a283a315af96eaea0e28e7163b21b</td>\n",
       "      <td>borzoi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>003df8b8a8b05244b1d920bb6cf451f9</td>\n",
       "      <td>basenji</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0042188c895a2f14ef64a918ed9c7b64</td>\n",
       "      <td>scottish_deerhound</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id               breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07         boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97               dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397            pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d            bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62    golden_retriever\n",
       "5  002211c81b498ef88e1b40b9abf84e1d  bedlington_terrier\n",
       "6  00290d3e1fdd27226ba27a8ce248ce85  bedlington_terrier\n",
       "7  002a283a315af96eaea0e28e7163b21b              borzoi\n",
       "8  003df8b8a8b05244b1d920bb6cf451f9             basenji\n",
       "9  0042188c895a2f14ef64a918ed9c7b64  scottish_deerhound"
      ]
     },
     "execution_count": 161,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('labels.csv')\n",
    "labels.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "sgdJIJNsMTY2",
    "outputId": "9f950f6d-4c93-4beb-9c36-a4fceaaf6bc4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scottish_deerhound      126\n",
       "maltese_dog             117\n",
       "afghan_hound            116\n",
       "entlebucher             115\n",
       "bernese_mountain_dog    114\n",
       "                       ... \n",
       "golden_retriever         67\n",
       "brabancon_griffon        67\n",
       "komondor                 67\n",
       "briard                   66\n",
       "eskimo_dog               66\n",
       "Name: breed, Length: 120, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['breed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kmSNWNQ_MXJ8",
    "outputId": "22e4ae50-9fdb-4e4d-c079-bace679fa2a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 163,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['breed'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "id": "jLZ36eOkMhV2",
    "outputId": "506b3ae5-1ffe-4feb-de73-19fae1460ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['boston_bull', 'dingo', 'pekinese', 'bluetick', 'golden_retriever',\n",
       "       'bedlington_terrier', 'borzoi', 'basenji', 'scottish_deerhound',\n",
       "       'shetland_sheepdog', 'walker_hound', 'maltese_dog',\n",
       "       'norfolk_terrier', 'african_hunting_dog',\n",
       "       'wire-haired_fox_terrier', 'redbone', 'lakeland_terrier', 'boxer',\n",
       "       'doberman', 'otterhound', 'standard_schnauzer',\n",
       "       'irish_water_spaniel', 'black-and-tan_coonhound', 'cairn',\n",
       "       'affenpinscher', 'labrador_retriever', 'ibizan_hound',\n",
       "       'english_setter', 'weimaraner', 'giant_schnauzer', 'groenendael',\n",
       "       'dhole', 'toy_poodle', 'border_terrier', 'tibetan_terrier',\n",
       "       'norwegian_elkhound', 'shih-tzu', 'irish_terrier', 'kuvasz',\n",
       "       'german_shepherd', 'greater_swiss_mountain_dog', 'basset',\n",
       "       'australian_terrier', 'schipperke', 'rhodesian_ridgeback',\n",
       "       'irish_setter', 'appenzeller', 'bloodhound', 'samoyed',\n",
       "       'miniature_schnauzer', 'brittany_spaniel', 'kelpie', 'papillon',\n",
       "       'border_collie', 'entlebucher', 'collie', 'malamute',\n",
       "       'welsh_springer_spaniel', 'chihuahua', 'saluki', 'pug', 'malinois',\n",
       "       'komondor', 'airedale', 'leonberg', 'mexican_hairless',\n",
       "       'bull_mastiff', 'bernese_mountain_dog',\n",
       "       'american_staffordshire_terrier', 'lhasa', 'cardigan',\n",
       "       'italian_greyhound', 'clumber', 'scotch_terrier', 'afghan_hound',\n",
       "       'old_english_sheepdog', 'saint_bernard', 'miniature_pinscher',\n",
       "       'eskimo_dog', 'irish_wolfhound', 'brabancon_griffon',\n",
       "       'toy_terrier', 'chow', 'flat-coated_retriever', 'norwich_terrier',\n",
       "       'soft-coated_wheaten_terrier', 'staffordshire_bullterrier',\n",
       "       'english_foxhound', 'gordon_setter', 'siberian_husky',\n",
       "       'newfoundland', 'briard', 'chesapeake_bay_retriever',\n",
       "       'dandie_dinmont', 'great_pyrenees', 'beagle', 'vizsla',\n",
       "       'west_highland_white_terrier', 'kerry_blue_terrier', 'whippet',\n",
       "       'sealyham_terrier', 'standard_poodle', 'keeshond',\n",
       "       'japanese_spaniel', 'miniature_poodle', 'pomeranian',\n",
       "       'curly-coated_retriever', 'yorkshire_terrier', 'pembroke',\n",
       "       'great_dane', 'blenheim_spaniel', 'silky_terrier',\n",
       "       'sussex_spaniel', 'german_short-haired_pointer', 'french_bulldog',\n",
       "       'bouvier_des_flandres', 'tibetan_mastiff', 'english_springer',\n",
       "       'cocker_spaniel', 'rottweiler'], dtype=object)"
      ]
     },
     "execution_count": 164,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels['breed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "oKTeWO__MmRL",
    "outputId": "6f02b51f-0b12-4fd3-b0c1-97f27d37dc5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scottish_deerhound',\n",
       " 'maltese_dog',\n",
       " 'afghan_hound',\n",
       " 'entlebucher',\n",
       " 'bernese_mountain_dog',\n",
       " 'shih-tzu',\n",
       " 'pomeranian',\n",
       " 'great_pyrenees',\n",
       " 'basenji',\n",
       " 'samoyed',\n",
       " 'airedale',\n",
       " 'tibetan_terrier',\n",
       " 'cairn',\n",
       " 'leonberg',\n",
       " 'japanese_spaniel',\n",
       " 'beagle',\n",
       " 'australian_terrier',\n",
       " 'miniature_pinscher',\n",
       " 'blenheim_spaniel',\n",
       " 'irish_wolfhound']"
      ]
     },
     "execution_count": 165,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(labels['breed'].value_counts().head(20).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "OsDjezJkM3Ke",
    "outputId": "608c0138-dde5-420d-84be-664901aa0bd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[126,\n",
       " 117,\n",
       " 116,\n",
       " 115,\n",
       " 114,\n",
       " 112,\n",
       " 111,\n",
       " 111,\n",
       " 110,\n",
       " 109,\n",
       " 107,\n",
       " 107,\n",
       " 106,\n",
       " 106,\n",
       " 105,\n",
       " 105,\n",
       " 102,\n",
       " 102,\n",
       " 102,\n",
       " 101]"
      ]
     },
     "execution_count": 166,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(labels['breed'].value_counts().head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "aTyUCTLzM_fc",
    "outputId": "e2db67ca-52ee-474e-eff9-10e41d95dad8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "10217    False\n",
       "10218    False\n",
       "10219     True\n",
       "10220     True\n",
       "10221    False\n",
       "Name: breed, Length: 10222, dtype: bool"
      ]
     },
     "execution_count": 167,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_breeds = list(labels['breed'].value_counts().head(20).index)\n",
    "labels.breed.isin(top_20_breeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZV7jG1tWNUA3"
   },
   "outputs": [],
   "source": [
    "labels_20_breed=labels[labels.breed.isin(top_20_breeds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "v9iWhBC4NkLm",
    "outputId": "6de52fa0-cd6d-44e9-de7f-66fc9d808bd1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2184"
      ]
     },
     "execution_count": 169,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels_20_breed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "colab_type": "code",
    "id": "QfAnR3hDOCO1",
    "outputId": "2e2a5519-65f6-40ea-dd7f-e63bfa781335"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9c86da4c88>"
      ]
     },
     "execution_count": 170,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAFjCAYAAADGh0tzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noIOEcQ+CIOggYdyDIAg6yP8HuAEqiu0Kxj0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_for_20_breed=labels_20_breed['breed'].value_counts()\n",
    "plot_for_20_breed.plot(kind= 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L3W3eHtONlOJ"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot\n",
    "# matplotlib.pyplot.bar(labels_20_breed['breed'],height = 100,orientation = 'horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9gGxFcxDdVKN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKYfwtNmdYV_"
   },
   "source": [
    "Get one hot Encoded for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SMER22WaNz4j"
   },
   "outputs": [],
   "source": [
    "# y(label) value should be one hot enocoded for fit \n",
    "\n",
    "dog_type = (labels['breed'])\n",
    "\n",
    "dog_type_hot_coded = pd.get_dummies(dog_type)\n",
    "#type(dog_type_hot_coded)\n",
    "dog_type_hot_coded_array = np.asarray(dog_type_hot_coded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWaJ9naXfoiU"
   },
   "source": [
    "## Preparing training dataset\n",
    "1. Write a code which reads each and every id from labels.csv file and loads the corresponding image (in RGB - 128, 128, 3) from the train folder. <br>\n",
    "2. Create 2 variables <br> \n",
    "     a.  x_train - Should have all the images of the dogs from train folder <br>\n",
    "     b.  y_train - Corresponding label of the dog <br>\n",
    "<u>Note:</u> The id of the dog images and its corresponding labels are available in labels.csv file   \n",
    "<u>Hint:</u> Watch the video shared on \"Preparing the training dataset\" if you face issue on creating the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "w3UT_nsTeW57",
    "outputId": "552c107c-459d-4e8a-b172-7788c10deafd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['000bec180eb18c7604dcecc8fe0dba07', 'boston_bull'],\n",
       "       ['001513dfcb2ffafc82cccf4d8bbaba97', 'dingo'],\n",
       "       ['001cdf01b096e06d78e9e5112d419397', 'pekinese'],\n",
       "       ...,\n",
       "       ['ffe2ca6c940cddfee68fa3cc6c63213f', 'airedale'],\n",
       "       ['ffe5f6d8e2bff356e9482a80a6e29aac', 'miniature_pinscher'],\n",
       "       ['fff43b07992508bc822f33d8ffd902ae', 'chesapeake_bay_retriever']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 173,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "neP2XRHTd4Cd",
    "outputId": "cc2e4137-5e58-4de2-d8bf-196310a68ac3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10222/10222 [00:28<00:00, 354.11it/s]\n"
     ]
    }
   ],
   "source": [
    "y_train_data = []\n",
    "X_train_data = []\n",
    "i=0\n",
    "for image,breed in tqdm(labels.values):\n",
    "  \n",
    "  img = cv2.imread('./train/{}.jpg'.format(image))\n",
    "  label = dog_type_hot_coded_array[i]\n",
    "  X_train_data.append(cv2.resize(img,(128,128)))\n",
    "  y_train_data.append(label)\n",
    "  i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "by7vc-pChpY0"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open('/content/drive/My Drive/computervision_assignment2/train.zip (Unzipped Files)/train/x_train_data.pickle','wb')\n",
    "pickle.dump(X_train_data,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open('/content/drive/My Drive/computervision_assignment2/test.zip (Unzipped Files)/test/y_test_data.pickle','wb')\n",
    "pickle.dump(y_train_data,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "\n",
    "\n",
    "# Pickle module implements  binary protocal for deserialization and serialization  of Python Objects\n",
    "# Serialization(Pickling) : Converting the python object into byte stream\n",
    "# Deserialization(Unpickling) : Inverse of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KmWO_GbJmhjx"
   },
   "source": [
    "##Normalize the training data and convert into 4 dimensions so that it can be used as an input to conv layers in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTfHq5PvlTmg"
   },
   "outputs": [],
   "source": [
    "# Normalizing the training data requires the X_train_data\n",
    "#X_train_data    # Their values ranges from 0 to 255\n",
    "# X_train_data = X_train_data.astype(int)/255\n",
    "  \n",
    "y_train_data = np.array(y_train_data)                             # Already one hot encoded, hence normalization is not needed\n",
    "X_train_data = np.array(X_train_data)\n",
    "X_train_data = X_train_data/255\n",
    "\n",
    "# print(X_train_data)                                             # Their values are between 0 to 1 \n",
    "# print(X_train_data.shape)                                       # The shape is found to be (10222, 128, 128, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cNxEjJMpqWZo"
   },
   "source": [
    "### Split the training and validation data from `x_train_data` and `y_train_data` obtained from above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WcC4KkR7o54X"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train,y_test = train_test_split(X_train_data,y_train_data,test_size=0.30, random_state =5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4nLz01bNq33E",
    "outputId": "81bee101-82df-4d0c-b390-d1092ecc5009"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7155, 128, 128, 3)"
      ]
     },
     "execution_count": 178,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wlEFW0mDq5A3",
    "outputId": "95cc78dc-143d-48a5-8d28-96305534e226"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3067, 128, 128, 3)"
      ]
     },
     "execution_count": 179,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xHTIhUFdq9Z4",
    "outputId": "9477a681-e149-4138-fda0-0d28ce5c8814"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7155, 120)"
      ]
     },
     "execution_count": 180,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ls7ExiCirEqc",
    "outputId": "b58dc2fa-5aaa-47f9-863e-7474861ccfd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7155, 120)"
      ]
     },
     "execution_count": 181,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DjlAOQJ-w2Qe"
   },
   "source": [
    "### Loading the test data\n",
    "Read the id column from the samples_submission.csv and store it in test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "S80-JWAcwfav",
    "outputId": "a14df967-a39c-4467-84da-c696c58d1b4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    000621fb3cbb32d8935728e48679680e\n",
       "1    00102ee9d8eb90812350685311fe5890\n",
       "2    0012a730dfa437f5f3613fb75efcd4ce\n",
       "3    001510bc8570bbeee98c8d80c8a95ec1\n",
       "4    001a5f3114548acdefa3d4da05474c2e\n",
       "5    00225dcd3e4d2410dd53239f95c0352f\n",
       "6    002c2a3117c2193b4d26400ce431eebd\n",
       "7    002c58d413a521ae8d1a5daeb35fc803\n",
       "8    002f80396f1e3db687c5932d7978b196\n",
       "9    0036c6bcec6031be9e62a257b1c3c442\n",
       "Name: id, dtype: object"
      ]
     },
     "execution_count": 182,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('sample_submission.csv')\n",
    "# test_data\n",
    "\n",
    "test_img = test_data['id']\n",
    "test_img.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qsFikaPfy3Ga",
    "outputId": "43b748bb-44a2-4426-87f2-73956e6c233f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10357/10357 [00:29<00:00, 345.58it/s]\n"
     ]
    }
   ],
   "source": [
    "#y_train_data = []\n",
    "X_test_data = []\n",
    "i=0\n",
    "for image in tqdm(test_img.values):\n",
    "  \n",
    "  img = cv2.imread('./test/{}.jpg'.format(image))\n",
    "  # label = dog_type_hot_coded_array[i]\n",
    "  X_test_data.append(cv2.resize(img,(128,128)))\n",
    "  # y_train_data.append(label)\n",
    "  # i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q89NcBtz0d7i"
   },
   "source": [
    "#Normalize the test data and convert it into 4 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFcOK5p90Nq_"
   },
   "outputs": [],
   "source": [
    "X_test_data = np.array(X_test)\n",
    "X_test_data = X_test_data/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e7FcWGYT0l0R"
   },
   "source": [
    "### Build a basic conv neural network with 2 conv layers (kernel sizes - 5 and 3) add layers as mentioned below for classification.\n",
    "\n",
    "1. Add a Dense layer with 256 neurons with `relu` activation\n",
    "\n",
    "2. Add a Dense layer with 120 neurons as final layer (as there are 120 classes in the given dataset) with `softmax` activation for classifiaction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "ZBSnvsGF0cEw",
    "outputId": "15b9f329-74f2-4178-d306-c3a166583a4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 124, 124, 32)      2432      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 124, 124, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 122, 122, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 61, 61, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 238144)            0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               60965120  \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 61,017,016\n",
      "Trainable params: 61,016,952\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#from tf.keras.models import Sequential\n",
    "input_shape = (128,128,3)                                                          # Height, width and channel\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(32,kernel_size=5,input_shape = input_shape,activation = 'relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(64,kernel_size=3,activation = 'relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(tf.keras.layers.Flatten())                                                 # Flattening for applying the input to the Dense layers\n",
    "model.add(tf.keras.layers.Dense(256,activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(120,activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9WMzol4V3QMv"
   },
   "source": [
    "### Use batch_size = 128 and epochs = 10 and execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "NcP1Cdgx3RSO",
    "outputId": "25112a8a-22cf-4bd6-cadc-f92bc0dd7c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/10\n",
      "7155/7155 [==============================] - 7s 975us/sample - loss: 4.8229 - accuracy: 0.0119 - val_loss: 4.7875 - val_accuracy: 0.0078\n",
      "Epoch 2/10\n",
      "7155/7155 [==============================] - 6s 891us/sample - loss: 4.7276 - accuracy: 0.0224 - val_loss: 4.7881 - val_accuracy: 0.0091\n",
      "Epoch 3/10\n",
      "7155/7155 [==============================] - 6s 896us/sample - loss: 4.6664 - accuracy: 0.0296 - val_loss: 4.7919 - val_accuracy: 0.0101\n",
      "Epoch 4/10\n",
      "7155/7155 [==============================] - 6s 890us/sample - loss: 4.6025 - accuracy: 0.0396 - val_loss: 4.8026 - val_accuracy: 0.0101\n",
      "Epoch 5/10\n",
      "7155/7155 [==============================] - 6s 891us/sample - loss: 4.5330 - accuracy: 0.0509 - val_loss: 4.8213 - val_accuracy: 0.0108\n",
      "Epoch 6/10\n",
      "7155/7155 [==============================] - 6s 889us/sample - loss: 4.4624 - accuracy: 0.0604 - val_loss: 4.8515 - val_accuracy: 0.0121\n",
      "Epoch 7/10\n",
      "7155/7155 [==============================] - 6s 890us/sample - loss: 4.3881 - accuracy: 0.0794 - val_loss: 4.8976 - val_accuracy: 0.0098\n",
      "Epoch 8/10\n",
      "7155/7155 [==============================] - 6s 893us/sample - loss: 4.3122 - accuracy: 0.0955 - val_loss: 4.9448 - val_accuracy: 0.0098\n",
      "Epoch 9/10\n",
      "7155/7155 [==============================] - 6s 889us/sample - loss: 4.2346 - accuracy: 0.1133 - val_loss: 5.0013 - val_accuracy: 0.0108\n",
      "Epoch 10/10\n",
      "7155/7155 [==============================] - 6s 894us/sample - loss: 4.1568 - accuracy: 0.1263 - val_loss: 5.0458 - val_accuracy: 0.0101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9c846ed668>"
      ]
     },
     "execution_count": 186,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=1e-6),loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, validation_data= [X_test_data,y_test], batch_size= batch_size , epochs= epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nc6h9GhO6ZiN"
   },
   "source": [
    "#The model accuracy is very poor !!!!\n",
    "### Use Data Augmentation in the above model to see if the accuracy improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GeX6BWOm3oEQ"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x2nT4RJy6hAl"
   },
   "outputs": [],
   "source": [
    "train_data_generator = ImageDataGenerator(rotation_range = 5,zoom_range =0.2,\n",
    "                                          horizontal_flip =False, fill_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JpzGb-hQ6g-J"
   },
   "outputs": [],
   "source": [
    "validation_data_generator = ImageDataGenerator(rotation_range = 5,zoom_range =0.2,\n",
    "                                          horizontal_flip =False, fill_mode = 'nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3HWCgDCE7enn"
   },
   "source": [
    "### Using the above objects, create the image generators with variable names `train_generator` and `val_generator`\n",
    "\n",
    "You need to use train_datagen.flow() and val_datagen.flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H2ovf7Js7SU-"
   },
   "outputs": [],
   "source": [
    "train_generator = train_data_generator.flow(X_train,y_train)\n",
    "val_generator        = validation_data_generator.flow(X_test_data,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31Dw7jXN8EOZ"
   },
   "source": [
    "### Fit the model using fit_generator() using `train_generator` and `val_generator` from the above step with 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "nakFVtGi79sO",
    "outputId": "7035f666-b3fd-4cf1-9bfc-db84bc8e26c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 224 steps, validate for 96 steps\n",
      "Epoch 1/10\n",
      "224/224 [==============================] - 33s 146ms/step - loss: 4.4223 - accuracy: 0.0591 - val_loss: 5.2211 - val_accuracy: 0.0108\n",
      "Epoch 2/10\n",
      "224/224 [==============================] - 31s 140ms/step - loss: 4.3199 - accuracy: 0.0783 - val_loss: 5.2713 - val_accuracy: 0.0101\n",
      "Epoch 3/10\n",
      "224/224 [==============================] - 32s 144ms/step - loss: 4.2484 - accuracy: 0.0900 - val_loss: 5.3130 - val_accuracy: 0.0101\n",
      "Epoch 4/10\n",
      "224/224 [==============================] - 32s 144ms/step - loss: 4.1834 - accuracy: 0.0980 - val_loss: 5.4202 - val_accuracy: 0.0101\n",
      "Epoch 5/10\n",
      "224/224 [==============================] - 32s 142ms/step - loss: 4.1270 - accuracy: 0.1041 - val_loss: 5.4788 - val_accuracy: 0.0101\n",
      "Epoch 6/10\n",
      "224/224 [==============================] - 31s 139ms/step - loss: 4.0649 - accuracy: 0.1185 - val_loss: 5.5127 - val_accuracy: 0.0108\n",
      "Epoch 7/10\n",
      "224/224 [==============================] - 32s 142ms/step - loss: 4.0331 - accuracy: 0.1229 - val_loss: 5.5550 - val_accuracy: 0.0108\n",
      "Epoch 8/10\n",
      "224/224 [==============================] - 33s 146ms/step - loss: 3.9847 - accuracy: 0.1315 - val_loss: 5.5772 - val_accuracy: 0.0108\n",
      "Epoch 9/10\n",
      "224/224 [==============================] - 32s 142ms/step - loss: 3.9342 - accuracy: 0.1466 - val_loss: 5.6136 - val_accuracy: 0.0108\n",
      "Epoch 10/10\n",
      "224/224 [==============================] - 31s 140ms/step - loss: 3.8798 - accuracy: 0.1514 - val_loss: 5.7412 - val_accuracy: 0.0108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9c84649748>"
      ]
     },
     "execution_count": 191,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator,validation_data = val_generator ,verbose = 1, epochs=10 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r9E5RTn8AsLN"
   },
   "source": [
    "# Model accuracy is still poor!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BrmV7i5oAsPW"
   },
   "source": [
    "### Lets use Transfer Learning\n",
    "\n",
    "Download the vgg wieght file from here : https://github.com/MinerKasch/applied_deep_learning/blob/master/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ldHppSSzA3oj"
   },
   "source": [
    "Use the below code to load VGG16 weights trained on ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_izhUVN19EWj"
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "\n",
    "project_path  = '/content/drive/My Drive/computervision_assignment2/'\n",
    "\n",
    "# Instantiate the model with the pre-trained weights (no top)\n",
    "base_model= tf.keras.applications.VGG16(weights=(project_path+'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'),\n",
    "                 include_top=False, pooling='avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Iemp0rNrCLNZ"
   },
   "source": [
    "Print the summary of the base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "colab_type": "code",
    "id": "kOPAQiVEA53J",
    "outputId": "8dc2c773-41b2-47fd-a50a-54547f4672d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zkzVAsH_CTex"
   },
   "source": [
    "### Add the following classification layers to the imported VGG Model <br>\n",
    "1. Flatten Layer\n",
    "2. Dense layer with 1024 neurons with activation as Relu\n",
    "3. Dense layer with 256 neurons with activation as Relu\n",
    "4. Dense layer with 120 neurons with activation as Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "REVAaA6kCO-i"
   },
   "outputs": [],
   "source": [
    "# base_model.add(tf.keras.layers.Flatten()) \n",
    "# base_model.add(tf.keras.layers.Dense(1024,activation = 'relu'))\n",
    "# base_model.add(tf.keras.layers.Dense(256,activation = 'relu'))\n",
    "# base_model.add(tf.keras.layers.Dense(120,activation = 'softmax'))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aglgGpq8C2sl"
   },
   "source": [
    "### Make all the layers in the base_model (VGG16) to be non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "ft4UKRlECjo4",
    "outputId": "ab758b0f-7747-499d-b203-ea06eeaff452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 15,533,240\n",
      "Trainable params: 818,552\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = False\n",
    "# \n",
    "model1 = tf.keras.models.Sequential()\n",
    "model1.add(base_model)\n",
    "model1.add(tf.keras.layers.Dense(1024,activation = 'relu'))\n",
    "model1.add(tf.keras.layers.Dense(256,activation = 'relu'))\n",
    "model1.add(tf.keras.layers.Dense(120,activation = 'softmax'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "AyOwNKhaEUBh",
    "outputId": "f7736628-79b3-498e-8c86-2d66f5c86ede"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/10\n",
      "7155/7155 [==============================] - 9s 1ms/sample - loss: 4.8402 - accuracy: 0.0075 - val_loss: 4.8312 - val_accuracy: 0.0065\n",
      "Epoch 2/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 4.8371 - accuracy: 0.0075 - val_loss: 4.8296 - val_accuracy: 0.0065\n",
      "Epoch 3/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 4.8342 - accuracy: 0.0078 - val_loss: 4.8281 - val_accuracy: 0.0065\n",
      "Epoch 4/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 4.8315 - accuracy: 0.0075 - val_loss: 4.8266 - val_accuracy: 0.0065\n",
      "Epoch 5/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 4.8289 - accuracy: 0.0075 - val_loss: 4.8252 - val_accuracy: 0.0065\n",
      "Epoch 6/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 4.8264 - accuracy: 0.0074 - val_loss: 4.8239 - val_accuracy: 0.0065\n",
      "Epoch 7/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 4.8241 - accuracy: 0.0074 - val_loss: 4.8227 - val_accuracy: 0.0065\n",
      "Epoch 8/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 4.8218 - accuracy: 0.0077 - val_loss: 4.8215 - val_accuracy: 0.0065\n",
      "Epoch 9/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 4.8196 - accuracy: 0.0074 - val_loss: 4.8204 - val_accuracy: 0.0065\n",
      "Epoch 10/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 4.8176 - accuracy: 0.0074 - val_loss: 4.8193 - val_accuracy: 0.0065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9c86952d30>"
      ]
     },
     "execution_count": 196,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "model1.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=1e-6),loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "model1.fit(X_train,y_train, validation_data= [X_test_data,y_test], batch_size= batch_size , epochs= epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sNiCTv88GgvS"
   },
   "outputs": [],
   "source": [
    "#Changing the optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "vuzxP4XWHCWf",
    "outputId": "8a8d399b-65e6-47d6-c395-78b0f11d4a3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/10\n",
      "7155/7155 [==============================] - 9s 1ms/sample - loss: 4.7127 - accuracy: 0.0246 - val_loss: 4.8487 - val_accuracy: 0.0098\n",
      "Epoch 2/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 4.2680 - accuracy: 0.0700 - val_loss: 4.9633 - val_accuracy: 0.0059\n",
      "Epoch 3/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 3.8585 - accuracy: 0.1242 - val_loss: 5.1534 - val_accuracy: 0.0075\n",
      "Epoch 4/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 3.5774 - accuracy: 0.1645 - val_loss: 5.3385 - val_accuracy: 0.0085\n",
      "Epoch 5/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 3.3605 - accuracy: 0.1980 - val_loss: 5.3911 - val_accuracy: 0.0052\n",
      "Epoch 6/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 3.1924 - accuracy: 0.2288 - val_loss: 5.3307 - val_accuracy: 0.0108\n",
      "Epoch 7/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 3.0379 - accuracy: 0.2562 - val_loss: 5.5241 - val_accuracy: 0.0088\n",
      "Epoch 8/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 2.9194 - accuracy: 0.2798 - val_loss: 5.8261 - val_accuracy: 0.0068\n",
      "Epoch 9/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 2.8116 - accuracy: 0.2922 - val_loss: 5.8879 - val_accuracy: 0.0088\n",
      "Epoch 10/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 2.7145 - accuracy: 0.3268 - val_loss: 5.5649 - val_accuracy: 0.0104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9c842a7160>"
      ]
     },
     "execution_count": 198,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "model1.compile(optimizer= 'rmsprop',loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "model1.fit(X_train,y_train, validation_data= [X_test_data,y_test], batch_size= batch_size , epochs= epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "-bQPWRZWHJL-",
    "outputId": "df852652-6d3a-48ac-f2aa-1b8efa5fe361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 120)               30840     \n",
      "=================================================================\n",
      "Total params: 15,533,240\n",
      "Trainable params: 818,552\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = False\n",
    "# \n",
    "model2 = tf.keras.models.Sequential()\n",
    "model2.add(base_model)\n",
    "model2.add(tf.keras.layers.Dense(1024,activation = 'relu'))\n",
    "model2.add(tf.keras.layers.Dense(256,activation = 'relu'))\n",
    "model2.add(tf.keras.layers.Dense(120,activation = 'sigmoid'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "KotQsvM4p3jA",
    "outputId": "86fd38a2-3c1a-4a39-96e6-6bc1cd3ed7c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7155 samples, validate on 3067 samples\n",
      "Epoch 1/10\n",
      "7155/7155 [==============================] - 9s 1ms/sample - loss: 4.7433 - accuracy: 0.0182 - val_loss: 4.8345 - val_accuracy: 0.0108\n",
      "Epoch 2/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 4.3560 - accuracy: 0.0584 - val_loss: 4.9687 - val_accuracy: 0.0095\n",
      "Epoch 3/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 3.9203 - accuracy: 0.1054 - val_loss: 5.1019 - val_accuracy: 0.0075\n",
      "Epoch 4/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 3.6189 - accuracy: 0.1469 - val_loss: 5.2620 - val_accuracy: 0.0075\n",
      "Epoch 5/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 3.3909 - accuracy: 0.1905 - val_loss: 5.3162 - val_accuracy: 0.0075\n",
      "Epoch 6/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 3.2244 - accuracy: 0.2173 - val_loss: 5.2948 - val_accuracy: 0.0108\n",
      "Epoch 7/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 3.1032 - accuracy: 0.2363 - val_loss: 5.5252 - val_accuracy: 0.0108\n",
      "Epoch 8/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 2.9843 - accuracy: 0.2576 - val_loss: 5.4270 - val_accuracy: 0.0085\n",
      "Epoch 9/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 2.8639 - accuracy: 0.2783 - val_loss: 5.5048 - val_accuracy: 0.0075\n",
      "Epoch 10/10\n",
      "7155/7155 [==============================] - 8s 1ms/sample - loss: 2.7650 - accuracy: 0.2949 - val_loss: 5.7507 - val_accuracy: 0.0095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9c84133048>"
      ]
     },
     "execution_count": 200,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "model2.compile(optimizer= 'rmsprop',loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "model2.fit(X_train,y_train, validation_data= [X_test_data,y_test], batch_size= batch_size , epochs= epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6JvJwKqhp8Jj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "DogBreedClassification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
